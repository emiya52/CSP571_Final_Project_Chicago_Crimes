{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/emiya/Desktop/cs584-project/run.ipynb Cell 1\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/emiya/Desktop/cs584-project/run.ipynb#W0sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m models \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/emiya/Desktop/cs584-project/run.ipynb#W0sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mMultinomial Logistic Regression\u001b[39m\u001b[39m'\u001b[39m: LogisticRegression(multi_class\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmultinomial\u001b[39m\u001b[39m'\u001b[39m, max_iter\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/emiya/Desktop/cs584-project/run.ipynb#W0sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     \u001b[39m#'Decision Tree': DecisionTreeClassifier(),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/emiya/Desktop/cs584-project/run.ipynb#W0sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     \u001b[39m#'Neural Network': MLPClassifier(max_iter=1000)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/emiya/Desktop/cs584-project/run.ipynb#W0sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/emiya/Desktop/cs584-project/run.ipynb#W0sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39mfor\u001b[39;00m name, model \u001b[39min\u001b[39;00m models\u001b[39m.\u001b[39mitems():\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/emiya/Desktop/cs584-project/run.ipynb#W0sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/emiya/Desktop/cs584-project/run.ipynb#W0sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     predictions_validation \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_val)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/emiya/Desktop/cs584-project/run.ipynb#W0sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m     predictions_test \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1303\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1301\u001b[0m     n_threads \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1303\u001b[0m fold_coefs_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, prefer\u001b[39m=\u001b[39;49mprefer)(\n\u001b[1;32m   1304\u001b[0m     path_func(\n\u001b[1;32m   1305\u001b[0m         X,\n\u001b[1;32m   1306\u001b[0m         y,\n\u001b[1;32m   1307\u001b[0m         pos_class\u001b[39m=\u001b[39;49mclass_,\n\u001b[1;32m   1308\u001b[0m         Cs\u001b[39m=\u001b[39;49m[C_],\n\u001b[1;32m   1309\u001b[0m         l1_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_ratio,\n\u001b[1;32m   1310\u001b[0m         fit_intercept\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[1;32m   1311\u001b[0m         tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[1;32m   1312\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m   1313\u001b[0m         solver\u001b[39m=\u001b[39;49msolver,\n\u001b[1;32m   1314\u001b[0m         multi_class\u001b[39m=\u001b[39;49mmulti_class,\n\u001b[1;32m   1315\u001b[0m         max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m   1316\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m   1317\u001b[0m         check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1318\u001b[0m         random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[1;32m   1319\u001b[0m         coef\u001b[39m=\u001b[39;49mwarm_start_coef_,\n\u001b[1;32m   1320\u001b[0m         penalty\u001b[39m=\u001b[39;49mpenalty,\n\u001b[1;32m   1321\u001b[0m         max_squared_sum\u001b[39m=\u001b[39;49mmax_squared_sum,\n\u001b[1;32m   1322\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1323\u001b[0m         n_threads\u001b[39m=\u001b[39;49mn_threads,\n\u001b[1;32m   1324\u001b[0m     )\n\u001b[1;32m   1325\u001b[0m     \u001b[39mfor\u001b[39;49;00m class_, warm_start_coef_ \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(classes_, warm_start_coef)\n\u001b[1;32m   1326\u001b[0m )\n\u001b[1;32m   1328\u001b[0m fold_coefs_, _, n_iter_ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mfold_coefs_)\n\u001b[1;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(n_iter_, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:452\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    448\u001b[0m l2_reg_strength \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C\n\u001b[1;32m    449\u001b[0m iprint \u001b[39m=\u001b[39m [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m100\u001b[39m, \u001b[39m101\u001b[39m][\n\u001b[1;32m    450\u001b[0m     np\u001b[39m.\u001b[39msearchsorted(np\u001b[39m.\u001b[39marray([\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m]), verbose)\n\u001b[1;32m    451\u001b[0m ]\n\u001b[0;32m--> 452\u001b[0m opt_res \u001b[39m=\u001b[39m optimize\u001b[39m.\u001b[39;49mminimize(\n\u001b[1;32m    453\u001b[0m     func,\n\u001b[1;32m    454\u001b[0m     w0,\n\u001b[1;32m    455\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mL-BFGS-B\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    456\u001b[0m     jac\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    457\u001b[0m     args\u001b[39m=\u001b[39;49m(X, target, sample_weight, l2_reg_strength, n_threads),\n\u001b[1;32m    458\u001b[0m     options\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39miprint\u001b[39;49m\u001b[39m\"\u001b[39;49m: iprint, \u001b[39m\"\u001b[39;49m\u001b[39mgtol\u001b[39;49m\u001b[39m\"\u001b[39;49m: tol, \u001b[39m\"\u001b[39;49m\u001b[39mmaxiter\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_iter},\n\u001b[1;32m    459\u001b[0m )\n\u001b[1;32m    460\u001b[0m n_iter_i \u001b[39m=\u001b[39m _check_optimize_result(\n\u001b[1;32m    461\u001b[0m     solver,\n\u001b[1;32m    462\u001b[0m     opt_res,\n\u001b[1;32m    463\u001b[0m     max_iter,\n\u001b[1;32m    464\u001b[0m     extra_warning_msg\u001b[39m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[1;32m    465\u001b[0m )\n\u001b[1;32m    466\u001b[0m w0, loss \u001b[39m=\u001b[39m opt_res\u001b[39m.\u001b[39mx, opt_res\u001b[39m.\u001b[39mfun\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/optimize/_minimize.py:710\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    707\u001b[0m     res \u001b[39m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    708\u001b[0m                              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[1;32m    709\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39ml-bfgs-b\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 710\u001b[0m     res \u001b[39m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m    711\u001b[0m                            callback\u001b[39m=\u001b[39;49mcallback, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[1;32m    712\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtnc\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    713\u001b[0m     res \u001b[39m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[39m=\u001b[39mcallback,\n\u001b[1;32m    714\u001b[0m                         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py:365\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    359\u001b[0m task_str \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m    360\u001b[0m \u001b[39mif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFG\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    361\u001b[0m     \u001b[39m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[39m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     \u001b[39m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m     \u001b[39m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 365\u001b[0m     f, g \u001b[39m=\u001b[39m func_and_grad(x)\n\u001b[1;32m    366\u001b[0m \u001b[39melif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNEW_X\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    367\u001b[0m     \u001b[39m# new iteration\u001b[39;00m\n\u001b[1;32m    368\u001b[0m     n_iterations \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39marray_equal(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx):\n\u001b[1;32m    284\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 285\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun()\n\u001b[1;32m    286\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_grad()\n\u001b[1;32m    287\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_fun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun_impl()\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[39m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[39m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[39m=\u001b[39m fun(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    138\u001b[0m \u001b[39m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/optimize/_optimize.py:77\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39margs):\n\u001b[1;32m     76\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_if_needed(x, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     78\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/optimize/_optimize.py:71\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mall(x \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(x)\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m---> 71\u001b[0m     fg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfun(x, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     72\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39m=\u001b[39m fg[\u001b[39m1\u001b[39m]\n\u001b[1;32m     73\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39m=\u001b[39m fg[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:279\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m     weights, intercept \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight_intercept(coef)\n\u001b[0;32m--> 279\u001b[0m loss, grad_pointwise \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_loss\u001b[39m.\u001b[39;49mloss_gradient(\n\u001b[1;32m    280\u001b[0m     y_true\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    281\u001b[0m     raw_prediction\u001b[39m=\u001b[39;49mraw_prediction,\n\u001b[1;32m    282\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    283\u001b[0m     n_threads\u001b[39m=\u001b[39;49mn_threads,\n\u001b[1;32m    284\u001b[0m )\n\u001b[1;32m    285\u001b[0m loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39msum()\n\u001b[1;32m    286\u001b[0m loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ml2_penalty(weights, l2_reg_strength)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/_loss/loss.py:200\u001b[0m, in \u001b[0;36mBaseLoss.loss_gradient\u001b[0;34m(self, y_true, raw_prediction, sample_weight, loss_out, gradient_out, n_threads)\u001b[0m\n\u001b[1;32m    190\u001b[0m         raw_prediction \u001b[39m=\u001b[39m raw_prediction\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\n\u001b[1;32m    192\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcloss\u001b[39m.\u001b[39mloss(\n\u001b[1;32m    193\u001b[0m         y_true\u001b[39m=\u001b[39my_true,\n\u001b[1;32m    194\u001b[0m         raw_prediction\u001b[39m=\u001b[39mraw_prediction,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    197\u001b[0m         n_threads\u001b[39m=\u001b[39mn_threads,\n\u001b[1;32m    198\u001b[0m     )\n\u001b[0;32m--> 200\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss_gradient\u001b[39m(\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    202\u001b[0m     y_true,\n\u001b[1;32m    203\u001b[0m     raw_prediction,\n\u001b[1;32m    204\u001b[0m     sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    205\u001b[0m     loss_out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    206\u001b[0m     gradient_out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    207\u001b[0m     n_threads\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    208\u001b[0m ):\n\u001b[1;32m    209\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute loss and gradient w.r.t. raw_prediction for each input.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \n\u001b[1;32m    211\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39m        Element-wise gradients.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[39mif\u001b[39;00m loss_out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "years = [2022, 2021, 2020]\n",
    "# Number of folds\n",
    "n_folds = 5\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each year, read the corresponding file and append to the list\n",
    "for year in years:\n",
    "    file_path = f'cleaned_datasets/Cleaned_Crimes_{year}.csv'  # Adjust the file path as needed\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list into one\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Parse the date column to extract day, month, and year\n",
    "combined_df['Date'] = pd.to_datetime(combined_df['Date'])\n",
    "combined_df['Day'] = combined_df['Date'].dt.day\n",
    "combined_df['Month'] = combined_df['Date'].dt.month\n",
    "combined_df['Year'] = combined_df['Date'].dt.year\n",
    "\n",
    "combined_df['Location Description'], _ = pd.factorize(combined_df['Location Description'])\n",
    "combined_df['Primary Type'], _ = pd.factorize(combined_df['Primary Type'])\n",
    "\n",
    "# Selecting relevant columns\n",
    "features = ['Community Area', 'Location Description', 'Day', 'Month', 'Year']\n",
    "target = 'Primary Type'\n",
    "\n",
    "# Split the dataset\n",
    "X = combined_df[features]\n",
    "y = combined_df[target]\n",
    "\n",
    "# Scale the features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.4, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "# models to train\n",
    "models = {\n",
    "    'Multinomial Logistic Regression': LogisticRegression(multi_class='multinomial', max_iter=1000),\n",
    "    #'Decision Tree': DecisionTreeClassifier(),\n",
    "    #'Random Forest': RandomForestClassifier(),\n",
    "    #'Naïve Bayes': MultinomialNB(),\n",
    "    #'K-nearest Neighbors': KNeighborsClassifier(),\n",
    "    #'Support Vector Machine': SVC(),\n",
    "    #'Neural Network': MLPClassifier(max_iter=1000)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions_validation = model.predict(X_val)\n",
    "    predictions_test = model.predict(X_test)\n",
    "    print(\"Model: \",name)\n",
    "    print(\"Predictions for X_val:\")\n",
    "    print(predictions_validation)\n",
    "    print(\"Accuracy:\", accuracy_score(y_val, predictions_validation))\n",
    "    print(\"Classification Report:\\n\\n\", classification_report(y_val, predictions_validation))\n",
    "    print(\"\\n\" + \"-\"*55 + \"\\n\")\n",
    "    print(\"Predictions for X_test:\")\n",
    "    print(predictions_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, predictions_test))\n",
    "    print(\"Classification Report:\\n\\n\", classification_report(y_test, predictions_test))\n",
    "    print(\"\\n\" + \"-\"*55 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models to train\n",
    "models = {\n",
    "    #'Multinomial Logistic Regression': LogisticRegression(multi_class='multinomial', max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    #'Random Forest': RandomForestClassifier(),\n",
    "    #'Naïve Bayes': MultinomialNB(),\n",
    "    #'K-nearest Neighbors': KNeighborsClassifier(),\n",
    "    #'Support Vector Machine': SVC(),\n",
    "    #'Neural Network': MLPClassifier(max_iter=1000)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions_validation = model.predict(X_val)\n",
    "    predictions_test = model.predict(X_test)\n",
    "    print(\"Model: \",name)\n",
    "    print(\"Predictions for X_val:\")\n",
    "    print(predictions_validation)\n",
    "    print(\"Accuracy:\", accuracy_score(y_val, predictions_validation))\n",
    "    print(\"Classification Report:\\n\\n\", classification_report(y_val, predictions_validation))\n",
    "    print(\"\\n\" + \"-\"*55 + \"\\n\")\n",
    "    print(\"Predictions for X_test:\")\n",
    "    print(predictions_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, predictions_test))\n",
    "    print(\"Classification Report:\\n\\n\", classification_report(y_test, predictions_test))\n",
    "    print(\"\\n\" + \"-\"*55 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models to train\n",
    "models = {\n",
    "    #'Multinomial Logistic Regression': LogisticRegression(multi_class='multinomial', max_iter=1000),\n",
    "    #'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    #'Naïve Bayes': MultinomialNB(),\n",
    "    #'K-nearest Neighbors': KNeighborsClassifier(),\n",
    "    #'Support Vector Machine': SVC(),\n",
    "    #'Neural Network': MLPClassifier(max_iter=1000)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions_validation = model.predict(X_val)\n",
    "    predictions_test = model.predict(X_test)\n",
    "    print(\"Model: \",name)\n",
    "    print(\"Predictions for X_val:\")\n",
    "    print(predictions_validation)\n",
    "    print(\"Accuracy:\", accuracy_score(y_val, predictions_validation))\n",
    "    print(\"Classification Report:\\n\\n\", classification_report(y_val, predictions_validation))\n",
    "    print(\"\\n\" + \"-\"*55 + \"\\n\")\n",
    "    print(\"Predictions for X_test:\")\n",
    "    print(predictions_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, predictions_test))\n",
    "    print(\"Classification Report:\\n\\n\", classification_report(y_test, predictions_test))\n",
    "    print(\"\\n\" + \"-\"*55 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models to train\n",
    "models = {\n",
    "    #'Multinomial Logistic Regression': LogisticRegression(multi_class='multinomial', max_iter=1000),\n",
    "    #'Decision Tree': DecisionTreeClassifier(),\n",
    "    #'Random Forest': RandomForestClassifier(),\n",
    "    'Naïve Bayes': MultinomialNB(),\n",
    "    #'K-nearest Neighbors': KNeighborsClassifier(),\n",
    "    #'Support Vector Machine': SVC(),\n",
    "    #'Neural Network': MLPClassifier(max_iter=1000)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions_validation = model.predict(X_val)\n",
    "    predictions_test = model.predict(X_test)\n",
    "    print(\"Model: \",name)\n",
    "    print(\"Predictions for X_val:\")\n",
    "    print(predictions_validation)\n",
    "    print(\"Accuracy:\", accuracy_score(y_val, predictions_validation))\n",
    "    print(\"Classification Report:\\n\\n\", classification_report(y_val, predictions_validation))\n",
    "    print(\"\\n\" + \"-\"*55 + \"\\n\")\n",
    "    print(\"Predictions for X_test:\")\n",
    "    print(predictions_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, predictions_test))\n",
    "    print(\"Classification Report:\\n\\n\", classification_report(y_test, predictions_test))\n",
    "    print(\"\\n\" + \"-\"*55 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models to train\n",
    "models = {\n",
    "    #'Multinomial Logistic Regression': LogisticRegression(multi_class='multinomial', max_iter=1000),\n",
    "    #'Decision Tree': DecisionTreeClassifier(),\n",
    "    #'Random Forest': RandomForestClassifier(),\n",
    "    #'Naïve Bayes': MultinomialNB(),\n",
    "    'K-nearest Neighbors': KNeighborsClassifier(),\n",
    "    #'Support Vector Machine': SVC(),\n",
    "    #'Neural Network': MLPClassifier(max_iter=1000)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions_validation = model.predict(X_val)\n",
    "    predictions_test = model.predict(X_test)\n",
    "    print(\"Model: \",name)\n",
    "    print(\"Predictions for X_val:\")\n",
    "    print(predictions_validation)\n",
    "    print(\"Accuracy:\", accuracy_score(y_val, predictions_validation))\n",
    "    print(\"Classification Report:\\n\\n\", classification_report(y_val, predictions_validation))\n",
    "    print(\"\\n\" + \"-\"*55 + \"\\n\")\n",
    "    print(\"Predictions for X_test:\")\n",
    "    print(predictions_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, predictions_test))\n",
    "    print(\"Classification Report:\\n\\n\", classification_report(y_test, predictions_test))\n",
    "    print(\"\\n\" + \"-\"*55 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models to train\n",
    "models = {\n",
    "    #'Multinomial Logistic Regression': LogisticRegression(multi_class='multinomial', max_iter=1000),\n",
    "    #'Decision Tree': DecisionTreeClassifier(),\n",
    "    #'Random Forest': RandomForestClassifier(),\n",
    "    #'Naïve Bayes': MultinomialNB(),\n",
    "    #'K-nearest Neighbors': KNeighborsClassifier(),\n",
    "    #'Support Vector Machine': SVC(),\n",
    "    'Neural Network': MLPClassifier(max_iter=1000)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions_validation = model.predict(X_val)\n",
    "    predictions_test = model.predict(X_test)\n",
    "    print(\"Model: \",name)\n",
    "    print(\"Predictions for X_val:\")\n",
    "    print(predictions_validation)\n",
    "    print(\"Accuracy:\", accuracy_score(y_val, predictions_validation))\n",
    "    print(\"Classification Report:\\n\\n\", classification_report(y_val, predictions_validation))\n",
    "    print(\"\\n\" + \"-\"*55 + \"\\n\")\n",
    "    print(\"Predictions for X_test:\")\n",
    "    print(predictions_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, predictions_test))\n",
    "    print(\"Classification Report:\\n\\n\", classification_report(y_test, predictions_test))\n",
    "    print(\"\\n\" + \"-\"*55 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
